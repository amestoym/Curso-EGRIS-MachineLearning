---
title: "Parcial intersemanal"
output: html_notebook
---

```{r}
#Se cargan las librerías a usar en la resolución de la guía.

library(readxl)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(vip)
```

```{r}
#Se carga la base de datos a utilizar
data = read.csv('datos.csv')
data
```
```{r}
str(data)
```


```{r}
#La información cuenta con 251 filas y 14 columnas, algunas con datos numéricos y otras con datos categóricos. En particular la columna "A_ESTRENAR" no tiene valores.
dim(data)
data = data[,-6]
data
```

```{r}
apply(data,2,function(x) {sum(x == "")})
```
```{r}
for (i in 6:8)
  {df_unique = data.frame(unique(data[,c(i)]))
  print(df_unique)}
for (i in 10:12)
  {df_unique = data.frame(unique(data[,c(i)]))
  print(df_unique)}
#for(i in 6:8)
#  print(unique(data[,c(i)]))
#for(i in 10:12)
#  print(unique(data[,c(i)]))
  
```


```{r}
#En el caso de las columnas con información categórica, como "BAUL", "COCHERA", "LAVADERO", "DEPENDENCIA", "TERRAZA", se introduce el texto "NO" para representar el caso en el que no se encuentra la característica en la vivienda. Dada la cantidad de filas vacías, se presupone que no son NA. Para "FRENTE_Y_CONTRA" se reemplazan los valores vacíos como "NA", ya que todas las opciones de ubicación están contempladas.

data = data.frame(apply(data, 2, function(x) gsub("^$|^ $", "NO", x)))
data[,c(6)] = sub("NO", NA, data[,c(6)])
data[, c(1:5,9)] <- sapply(data[, c(1:5,9)], as.integer)
data
```

```{r}
#Para las variables numéricas, se comienza mostrando el resumen clásico de parámetros descriptivos.
summary(data[,c(1:5,9)])
```
```{r}
#En particular, para la variable "AMBIENTES"
media_ambientes  = mean(data$AMBIENTES)
desvio_ambientes = sd(data$AMBIENTES)
rango_ambientes = max(data$AMBIENTES) - min(data$AMBIENTES)
mediana_ambientes = median(data$AMBIENTES)
cuartiles_ambientes = quantile(data$AMBIENTES,c(0.25,0.5,0.75))
distancia_intercuartil = quantile(data$AMBIENTES,0.75)-quantile(data$AMBIENTES,0.25)

print(paste("Media: ", media_ambientes))
print(paste("Mediana: ", mediana_ambientes))
print(paste("Desvío: ", desvio_ambientes))
print(paste("Rango: ", rango_ambientes))
print(paste("Cuartiles: ", cuartiles_ambientes))
print(paste("Distancia intercuartil: ", distancia_intercuartil))

```
```{r}
#Para describir visualmente la variable discreta ambientes se pueden utilizar dos gráficos: el histograma, para observar la frecuencia absoluta o relativa de cada rango de valores, y el boxplot, que muestra gráficamente la mediana, los cuartiles y también posibles outliers.

ggplot(data = data, aes(AMBIENTES)) +
  geom_histogram(aes(y=(..count..)/sum(..count..)), binwidth = 1, color="black", fill="blue") +
  labs(title="Histograma de frec. rel. de ambientes",x="Ambientes", y = "Frecuencia relativa")

ggplot(data=data, aes(x=AMBIENTES, y="")) + 
  geom_boxplot(col="grey",fill="blue")  + 
  labs(title="Boxplot")+
  scale_x_continuous(limits = c(1,8), breaks = seq(1, 8, by = 1))

```
```{r}
#Como la variable BARRIOS tiene sólo dos categorías, podría estudiarse si está asociada a AMBIENTE por medio de un boxplot o un histograma, observando cómo varía la distribución muestral de la variable numérica de acuerdo con el barrio correspondiente.


ggplot(data=data, aes(y=(..count..)/sum(..count..), x=data$AMBIENTES, group=data$BARRIOS, fill=data$BARRIOS)) +
  geom_histogram(binwidth=1, color= "black")+
  labs(title="Histograma de frec. rel. de ambientes por barrio",x="Ambientes", y = "Frecuencia relativa", fill="Barrio")

ggplot(data=data, aes(x=data$BARRIOS, y=data$AMBIENTES)) + 
  geom_boxplot(col="grey",fill="blue")  + 
  labs(title="Boxplot", y="Ambientes")+
  stat_summary(fun=mean, geom="point", shape=4, size=4,col="red")

```
```{r}
#Para analizar la independencia entre dos variables categóricas como BARRIOS y DEPENDENCIA se puede utilizar un gráfico de mosaico, que grafica las probabilidades condicionales. Es una representación gráfica de la tabla de contingencia.

table_cat = table(data$BARRIOS, data$DEPENDENCIA)

table_cat

mosaicplot(table_cat,main="Diag. mosaico para presencia de dependencia según barrio")

#Las proporciones son significativamente diferentes lo que indica una dependencia entre ambas variables. Es mucho menos probable que una vivienda tenga dependencia de servicio estando ubicada en San Nicolás que en Villa del Parque.

```
```{r}
data[,c(6:8,10:12)] <- lapply(data[,c(6:8,10:12)], factor)
data
```

```{r}
#Se eliminan las filas con valores NA de FRENTE_Y_CONTRA.
data <- data[complete.cases(data[,c(6)]),]
data
```
```{r}
i <- sapply(data, is.factor)
data[i] <- lapply(data[i], as.integer)
data
```
```{r}
data.pca = prcomp(data[,c(1:12)], scale=TRUE, center=TRUE)
data.pca
```
```{r}
round(data.pca$rotation,2)
```
```{r}
round(data.pca$center,2)
```


```{r}
summary(data.pca)
```
```{r}
#loadings
carga1 = data.frame(cbind(X=1:length(data[,c(1:12)]),
                          primeracarga=data.frame(data.pca$rotation)[,1]))
carga2 = data.frame(cbind(X=1:length(data[,c(1:12)]),
                          segundacarga=data.frame(data.pca$rotation)[,2]))
round(cbind(carga1,carga2),2)
```

```{r}
ggplot(carga1, aes(X,primeracarga) ,
       fill=x ) + geom_bar ( stat="identity" ,
       position="dodge" ,
       fill ="royalblue" ,
       width =0.5 ) +
xlab( 'variables originales' ) + ylab('Primeracarga ' )

ggplot(carga2,aes(X,segundacarga) ,
       fill =X ) + geom_bar(stat="identity",position="dodge",
       fill ="royalblue" ,
       width =0.5 ) +
xlab('variables originales') + ylab('Segundacarga')
```

```{r}
ggbiplot(data.pca, obs.scale=1 ,var.scale=1,alpha=0.5,
         groups=factor(data$BARRIOS)) +
scale_color_manual(name="Barrio", values=c("red","green"),labels=c("San Nicolás","Villa del Parque")) +  
theme(legend.direction ="horizontal", legend.position = "top")+
   xlim(-4,4)+
  ylim(-4,4)
```
```{r}
#A continuación, se crea un modelo de regresión múltiple con las variables numéricas y BARRIOS como predictoras para el precio del inmueble.
model = lm(data$DOLARES ~ data$M2 + data$AMBIENTES + data$DORMITORIO + data$ANTIGUEDAD + data$BANIOS + factor(data$BARRIOS))

summary(model)
```
```{r}
#De acuerdo a los resultados, se obtiene un buen ajuste para el modelo (de acuerdo con los valores de R2, F y p-value para la regresión), pero se identifican también variables que no son significativas: AMBIENTES, BARRIOS, DORMITORIO y BANIOS. En principio, se elimina la menos significativa para observar los cambios.

model = lm(data$DOLARES ~ data$M2 + data$DORMITORIO + data$ANTIGUEDAD + data$BANIOS + factor(data$BARRIOS))

summary(model)
```
```{r}
#Al eliminar AMBIENTES el modelo mejora mínimamente y el análisis indica que BANIOS y BARRIOS siguen sin ser significativas. Si se elimina la variable categórica barrio:

model = lm(data$DOLARES ~ data$M2 + data$DORMITORIO + data$BANIOS + data$ANTIGUEDAD)

summary(model)
```
```{r}
#Remover BARRIOS de las variables predictoras sí mejoró sensiblemente el ajuste, tal como se ve en el valor de R2 ajustado. Si se elimina también BANIOS que sigue sin ser significativa:

model = lm(data$DOLARES ~ data$M2 + data$DORMITORIO + data$ANTIGUEDAD)

summary(model)

#El ajuste de la regresión múltiple se mantiene en el mismo orden del modelo anterior, pero utilizando sólo tres variables predictoras para el precio de la vivienda: M2, DORMITORIO y ANTIGUEDAD.
```
```{r}
#A partir de las variables numéricas del dataset, se crea un árbol de decisión para clasificar un inmueble según BARRIOS.

data_num = data[,c(1:5,9,13)]
sample = sample.int(n = nrow(data_num), size = floor(.7*nrow(data_num)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]

modelo_arbol = rpart( factor(BARRIOS)~. ,train,
                 control=rpart.control(maxdepth=30,
                                       minsplit=1,
                                       minbucket=1,
                                       cp=-1),
                #parms=list(split="information") )
                 parms=list(split="gini")              )
tree_scores = predict(modelo_arbol,test, type="class")
rpart.plot(modelo_arbol,yesno=2)
summary(modelo_arbol)
tabla <- table(factor(test$BARRIOS),tree_scores)
confusionMatrix(tabla)
```

```{r}
printcp(modelo_arbol)
plotcp(modelo_arbol)
```

```{r}
#Se obtiene el árbol óptimo "podando" a partir del valor de complejidad que da el menor error de clasificación.
arbol_optimo <- prune(modelo_arbol,cp=modelo_arbol$cptable[which.min(modelo_arbol$cptable[,4]),1])
rpart.plot(arbol_optimo)
summary(arbol_optimo)
opt_tree_scores = predict(arbol_optimo,test, type="class")
tabla_opt <- table(factor(test$BARRIOS),opt_tree_scores)
confusionMatrix(tabla_opt)
```
```{r}
#Por último, se entrena un modelo de random forest para el clasificador.

modelo_rf = randomForest(factor(BARRIOS)~., data=train, importance=T)
print(modelo_rf)
vip(modelo_rf)
```
```{r}
pred_rf = predict(modelo_rf, test, type="class")
tabla_rf <- table(factor(test$BARRIOS),pred_rf)
confusionMatrix(tabla_rf)
```
```{r}
#Se optimiza el modelo de random forest ajustando mtry con la accuracy como métrica.

control <- trainControl(method='repeatedcv', 
                        number=10, 
                        repeats=3)

rf_caret <- train(factor(BARRIOS)~.,data=train,
                  method='rf',
                  metric="Accuracy",
                  tuneGrid=expand.grid(mtry=c(1,2,3,4,5,6,7,8,9)),
                  trControl=control)
print(rf_caret)
vip(rf_caret)
```
```{r}
pred_caret = predict(rf_caret, test)
tabla_caret <- table(factor(test$BARRIOS),pred_caret)
confusionMatrix(tabla_caret)
```

